"""
Knowledge Base Generator.

Generates UMBRA_KNOWLEDGE.md - a comprehensive file that serves as
the single source of truth for any LLM reading the project.
"""

import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from rich.console import Console

console = Console()

KNOWLEDGE_TEMPLATE = """# Umbra Knowledge Base

> **Auto-generated project intelligence** | Last sync: {timestamp}
> This file is the single source of truth for understanding this project.

## Quick Context (Read This First)

{quick_context}

---

## Architecture Diagram

```mermaid
{mermaid}
```

---

## Module Documentation

{module_docs}

---

## API Reference

{api_reference}

---

## Security Report

**Last Scan**: {security_timestamp}
**Overall Risk**: {risk_level}

{security_report}

---

## Code Metrics

| Metric | Value |
|--------|-------|
| Total Files | {total_files} |
| Total Lines | {total_lines} |
| Avg Lines/File | {avg_lines} |
| Entry Points | {entry_points} |
| External APIs | {external_apis} |

---

## Recent Activity

{recent_changes}

---

## File Index

<details>
<summary>Click to expand file list ({total_files} files)</summary>

{file_index}

</details>

---

*Generated by [Umbra](https://github.com/your-repo/umbra) - The Shadow Architect*
"""

SECURITY_ISSUE_TEMPLATE = """
### {risk_emoji} {file_path}

| Type | Description | Recommendation |
|------|-------------|----------------|
{issues_table}
"""


def format_security_report(security_data: List[Dict]) -> tuple[str, str]:
    """Format security scan results into markdown."""
    if not security_data:
        return "none", "No security issues detected. âœ“"
    
    # Calculate overall risk
    risk_levels = {"critical": 5, "high": 4, "medium": 3, "low": 2, "none": 1}
    max_risk = max(
        risk_levels.get(item.get("risk_level", "none"), 1)
        for item in security_data
    )
    
    risk_names = {5: "critical", 4: "high", 3: "medium", 2: "low", 1: "none"}
    overall_risk = risk_names[max_risk]
    
    # Filter files with issues
    files_with_issues = [d for d in security_data if d.get("issues")]
    
    if not files_with_issues:
        return "none", "No security issues detected. âœ“"
    
    report_parts = []
    risk_emojis = {
        "critical": "ðŸ”´",
        "high": "ðŸŸ ",
        "medium": "ðŸŸ¡",
        "low": "ðŸŸ¢",
        "none": "âœ“",
    }
    
    for item in files_with_issues:
        issues_rows = []
        for issue in item.get("issues", []):
            issues_rows.append(
                f"| {issue.get('type', 'Unknown')} | "
                f"{issue.get('description', 'N/A')} | "
                f"{issue.get('recommendation', 'Review manually')} |"
            )
        
        if issues_rows:
            report_parts.append(
                SECURITY_ISSUE_TEMPLATE.format(
                    risk_emoji=risk_emojis.get(item.get("risk_level", "none"), "?"),
                    file_path=item.get("file", "Unknown"),
                    issues_table="\n".join(issues_rows),
                )
            )
    
    return overall_risk, "\n".join(report_parts)


def format_recent_changes(changes: List[Dict]) -> str:
    """Format recent changes into markdown."""
    if not changes:
        return "No recent changes recorded."
    
    lines = ["| Time | File | Change | Description |", "|------|------|--------|-------------|"]
    
    for change in changes[:10]:
        time_str = change.get("timestamp", "??:??")
        if isinstance(time_str, datetime):
            time_str = time_str.strftime("%H:%M")
        elif isinstance(time_str, str) and len(time_str) > 5:
            time_str = time_str[-5:]  # Get HH:MM
        
        file_name = Path(change.get("file_path", "unknown")).name
        change_type = change.get("change_type", "modified")
        description = change.get("description", "No description")[:60]
        
        lines.append(f"| {time_str} | `{file_name}` | {change_type} | {description} |")
    
    return "\n".join(lines)


def format_file_index(files: List[str], root_path: str) -> str:
    """Format file list into a structured index."""
    if not files:
        return "No files indexed."
    
    # Group by directory
    groups: Dict[str, List[str]] = {}
    root = Path(root_path).resolve()
    
    for file_path in sorted(files):
        try:
            rel_path = Path(file_path).resolve().relative_to(root)
            parent = str(rel_path.parent) if rel_path.parent != Path(".") else "root"
            
            if parent not in groups:
                groups[parent] = []
            groups[parent].append(rel_path.name)
        except ValueError:
            # File outside root
            if "external" not in groups:
                groups["external"] = []
            groups["external"].append(Path(file_path).name)
    
    lines = []
    for group_name in sorted(groups.keys()):
        lines.append(f"\n**{group_name}/**")
        for file_name in sorted(groups[group_name]):
            lines.append(f"- `{file_name}`")
    
    return "\n".join(lines)


def generate_knowledge_file(
    output_path: str,
    mermaid: str,
    quick_context: str,
    module_docs: str,
    api_reference: str,
    security_data: List[Dict],
    metrics: Dict,
    recent_changes: List[Dict],
    file_list: List[str],
    root_path: str,
) -> bool:
    """Generate the complete UMBRA_KNOWLEDGE.md file."""
    try:
        path = Path(output_path)
        path.parent.mkdir(parents=True, exist_ok=True)
        
        # Format security report
        risk_level, security_report = format_security_report(security_data)
        
        # Format recent changes
        recent_changes_md = format_recent_changes(recent_changes)
        
        # Format file index
        file_index = format_file_index(file_list, root_path)
        
        # Calculate metrics
        total_files = metrics.get("total_files", len(file_list))
        total_lines = metrics.get("total_lines", 0)
        avg_lines = total_lines // total_files if total_files > 0 else 0
        
        content = KNOWLEDGE_TEMPLATE.format(
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            quick_context=quick_context or "Project context not generated yet.",
            mermaid=mermaid,
            module_docs=module_docs or "Documentation not generated yet. Run `umbra scan` with `--docs` flag.",
            api_reference=api_reference or "API reference not generated yet.",
            security_timestamp=datetime.now().strftime("%Y-%m-%d %H:%M"),
            risk_level=f"**{risk_level.upper()}**" if risk_level != "none" else "âœ“ Clean",
            security_report=security_report,
            total_files=total_files,
            total_lines=total_lines,
            avg_lines=avg_lines,
            entry_points=metrics.get("entry_points", 0),
            external_apis=metrics.get("external_apis", 0),
            recent_changes=recent_changes_md,
            file_index=file_index,
        )
        
        path.write_text(content, encoding="utf-8")
        console.print(f"[green]   Knowledge base updated: {path}[/green]")
        return True
        
    except Exception as e:
        console.print(f"[red]   Failed to write knowledge base: {e}[/red]")
        return False


def load_existing_knowledge(path: str) -> Dict:
    """Load existing knowledge base data."""
    knowledge = {
        "quick_context": "",
        "module_docs": "",
        "api_reference": "",
        "security_data": [],
        "recent_changes": [],
    }
    
    file_path = Path(path)
    if not file_path.exists():
        return knowledge
    
    try:
        content = file_path.read_text(encoding="utf-8")
        
        # Extract sections (basic parsing)
        sections = {
            "Quick Context": "quick_context",
            "Module Documentation": "module_docs", 
            "API Reference": "api_reference",
        }
        
        for header, key in sections.items():
            if f"## {header}" in content:
                start = content.index(f"## {header}") + len(f"## {header}")
                # Find next section
                rest = content[start:]
                end_markers = ["---", "## "]
                end = len(rest)
                for marker in end_markers:
                    if marker in rest:
                        marker_pos = rest.index(marker)
                        if marker_pos < end:
                            end = marker_pos
                
                knowledge[key] = rest[:end].strip()
                
                # Clean up "Read This First" suffix
                if "(Read This First)" in knowledge[key]:
                    knowledge[key] = knowledge[key].replace("(Read This First)", "").strip()
        
    except Exception:
        pass
    
    return knowledge

